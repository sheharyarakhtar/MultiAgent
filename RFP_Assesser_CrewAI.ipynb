{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sheharyarakhtar/MultiAgent/blob/main/RFP_Assesser_CrewAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "J6p5OfdKeuWb"
      },
      "outputs": [],
      "source": [
        "%pip -q install langchain langchain_community langchain_google_genai crewai crewai_tools faiss-gpu fastembed\n",
        "%pip -q install llama-index-embeddings-huggingface\n",
        "%pip -q install llama-index-embeddings-instructor\n",
        "%pip -q install -U duckduckgo-search\n",
        "%pip -q install langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b75bzo_-Ovt"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.vectorstores import VectorStoreRetriever\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import SerperDevTool, tool, PDFSearchTool\n",
        "import pathlib\n",
        "import textwrap\n",
        "import google.generativeai as genai\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from google.colab import userdata\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "from IPython.display import display, Markdown, Latex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RAG (Retrieval Augmented Generator) using PDFs"
      ],
      "metadata": {
        "id": "hpT0D3cKXZI9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TcxPnVzxlgJV"
      },
      "outputs": [],
      "source": [
        "class RFPAssesser:\n",
        "    def __init__(self, model_name, embeddings_model_name):\n",
        "        self.llm = ChatGoogleGenerativeAI(model=model_name,\n",
        "                                          verbose=True,\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "                                          temperature = 0.3)\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=embeddings_model_name,\n",
        "            show_progress=False\n",
        "            )\n",
        "        self.all_pages = []\n",
        "        self.vectorDB = None\n",
        "        self.retriever = None\n",
        "        self.assesser = None\n",
        "\n",
        "    def EmbedDocuments(self, paths):\n",
        "        for path in paths:\n",
        "            loader = PyPDFLoader(path)\n",
        "            pages = loader.load_and_split()\n",
        "            self.all_pages.extend(pages)\n",
        "            print(f\"Documents {path} loaded successfully!\")\n",
        "\n",
        "    def createVectorDB(self):\n",
        "      if not self.all_pages:\n",
        "          print(\"No documents loaded.\")\n",
        "          return\n",
        "      if not self.embeddings:\n",
        "          print(\"No embeddings provided.\")\n",
        "          return\n",
        "      embeddings = self.embeddings.embed_documents([page.page_content for page in self.all_pages])\n",
        "      if not embeddings:\n",
        "          print(\"Failed to generate embeddings.\")\n",
        "          return\n",
        "      self.vectorDB = FAISS.from_documents(self.all_pages, self.embeddings)\n",
        "      print(\"Vector store created!\")\n",
        "\n",
        "    def createRetriever(self):\n",
        "        self.retriever = VectorStoreRetriever(vectorstore=self.vectorDB)\n",
        "        self.assesser = RetrievalQA.from_chain_type(llm=self.llm, retriever=self.retriever)\n",
        "        print(\"Retriever created!\")\n",
        "\n",
        "    def setup(self, pdfs):\n",
        "        self.EmbedDocuments(paths=pdfs)\n",
        "        self.createVectorDB()\n",
        "        self.createRetriever()\n",
        "\n",
        "    def run(self, prompt):\n",
        "      return self.assesser.run(prompt)\n",
        "pdfs = [i for i in os.listdir() if 'pdf' in i]\n",
        "assesser = RFPAssesser(\n",
        "    model_name='gemini-1.5-flash',\n",
        "    embeddings_model_name=\"sentence-transformers/msmarco-distilbert-base-v4\"\n",
        "    )\n",
        "assesser.setup(pdfs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tools to be used by LLM Agents"
      ],
      "metadata": {
        "id": "ezNZibjRXhes"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p7HVVTgsf9h"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def Assesser(question: str, assesser = assesser) -> str:\n",
        "  \"\"\"\n",
        "  This tool allows you to query the provided documents.\n",
        "  You can ask it relevant questions and it will return the answer.\n",
        "  \"\"\"\n",
        "  prompt = f\"\"\"\"\n",
        "  Context: You are the owner of the RFP documents you have access to.\n",
        "  You will be asked questions regarding these documents.\n",
        "  You answer these questions by assessing the documents you have access to.\n",
        "\n",
        "  Question: {question}\n",
        "  \"\"\"\n",
        "  return assesser.run(prompt)\n",
        "\n",
        "@tool\n",
        "def DuckDuckGoSearch(search_query: str):\n",
        "    \"\"\"Search the web for information on a given topic\"\"\"\n",
        "\n",
        "    return DuckDuckGoSearchRun().run(search_query)\n",
        "\n",
        "serper_tool = SerperDevTool()\n",
        "\n",
        "import json\n",
        "\n",
        "@tool\n",
        "def SearchRFP(keywords: str, assesser = assesser) -> str:\n",
        "    \"\"\"\n",
        "    Search the RFP documents with keywords\n",
        "\n",
        "    keywords: str: Search keyword in the attached documents\n",
        "    conducts a similarity search of document and results a dictionary of relevant content with page numbers\n",
        "    \"\"\"\n",
        "    results = assesser.vectorDB.similarity_search(keywords)\n",
        "    overall = {}\n",
        "    content = \"\"\n",
        "    for result in results:\n",
        "      combine = {\n",
        "          'Page Number':result.metadata['page'],\n",
        "          'Content':result.page_content\n",
        "      }\n",
        "      overall[result.metadata['source']] = combine\n",
        "      content = content + result.page_content + \"\\n\\n\\n\"\n",
        "    prettyjson = json.dumps(overall, indent=4)\n",
        "    content = rephrase_text(content)\n",
        "    return content\n",
        "\n",
        "def rephrase_text(input_string, model = assesser.llm):\n",
        "  rephrased = model.invoke(\n",
        "        f\"\"\"\n",
        "        Context: You are a language model used to rephrase messy text.\n",
        "        You will be given some messy text and your job is to format it and paraphrase it.\n",
        "        Do not add anything yourself.\n",
        "        Remove things that are not relevant i.e. any tables or idle letters. Just rephrase the content in a single or max 2 paragraphs\n",
        "\n",
        "        Text: {input_string}\n",
        "        \"\"\").content\n",
        "  return rephrased\n",
        "\n",
        "@tool\n",
        "def write_to_file(input_string, file_path):\n",
        "    \"\"\"\n",
        "    Write input_string to a text file at file_path.\n",
        "\n",
        "    Parameters:\n",
        "    - input_string (str): The string to write to the file.\n",
        "    - file_path (str): The path where the file will be created or overwritten.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write(input_string)\n",
        "        print(f\"Successfully wrote to file: {file_path}\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error writing to file {file_path}: {e}\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def pdf_search(query: str, pdf_path: str) -> str:\n",
        "  \"\"\"\n",
        "  Pass in the query you wish you ask and the path to the PDF you wish to search the query in\n",
        "  query: string\n",
        "  pdf_path: string\n",
        "  The function will return a string explaining what the pdf says about the query\n",
        "  \"\"\"\n",
        "\n",
        "  return rag.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC9MoAEvvvOL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Agents and Tasks for Multi Agent Workflow"
      ],
      "metadata": {
        "id": "shgw10b5XmHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJTa24vCc_lZ"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', verbose=True,google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "pdfs = [i for i in os.listdir() if 'pdf' in i]\n",
        "rfp_assesser = Agent(\n",
        "    role = 'RFP Assesser',\n",
        "    goal=\"You are a Consultant in the {team_name} team. You need to ask relevant questions to the tool to assess if there are any use-cases related to you\",\n",
        "    backstory = (\n",
        "        \"You are a consultant in the {team_name} team\"\n",
        "        \"Clients come to you with their request for proposals\"\n",
        "        \"These documents contain their vision for their company, or problems they would like to solve\"\n",
        "        \"You are assigned a Assesser tool which you can use to interact with each pdf\"\n",
        "    ),\n",
        "    verbose = True,\n",
        "    memory = True,\n",
        "    llm = llm,\n",
        "    tools = [RFPAssesser]\n",
        ")\n",
        "summarise_usecases = Task(\n",
        "    description=(\n",
        "        \"Ask questions relevant to you from the data using the tools assigned. You need to find all cases relevant to you as part of the {team_name} team\"\n",
        "        \"The RFP does not answer all questions. Where the answers are unavailable, you make educated assumptions and move on.\"\n",
        "        \"You assess these documents to see where you, being part of the {team_name} team, can help solve some, if any, of these problems\"\n",
        "        ),\n",
        "    expected_output = \"A summary in markdown syntax detailing the use-cases that are relevant to your field, along with their page-numbers. Write these files using write_to_file tool\",\n",
        "    agent = rfp_assesser,\n",
        "    tools = [RFPAssesser]\n",
        ")\n",
        "crew = Crew(\n",
        "    agents = [rfp_assesser],\n",
        "    tasks = [summarise_usecases],\n",
        "    process = Process.sequential\n",
        ")\n",
        "crew.kickoff(inputs = {'team_name':'Data Science',\n",
        "                       'team_tools': 'Data Science',\n",
        "                       'pdfs': ', '.join(pdfs) })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A10iNQGBumzV"
      },
      "outputs": [],
      "source": [
        "pdfs = [i for i in os.listdir() if 'pdf' in i]\n",
        "', '.join(pdfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY_RjqsLnyZ2"
      },
      "outputs": [],
      "source": [
        "rfp_assesser = Agent(\n",
        "    role = 'RFP Assesser',\n",
        "    goal=\"You are a Consultant in the {team_name} team. You need to ask relevant questions to the tool to assess if there are any use-cases related to you\",\n",
        "    backstory = (\n",
        "\n",
        "        \"You are a consultant in the {team_name} team\"\n",
        "        \"Clients come to you with their request for proposals\"\n",
        "        \"These documents contain their vision for their company, or problems they would like to solve\"\n",
        "        \"You may ask relevant questions to the documents to assess its relevance to your field using the Assesser tool\"\n",
        "        \"You dont present a solution for a problem that the client has not explicitly asked you to solve\"\n",
        "        \"If there is no problem mentioned explicitly related to your field, you may use the Assesser tool to find which potential use-cases can be created\"\n",
        "        \"You also have direct access to the RFP using the SearchRFP tool which results content directly from the document in a string format\"\n",
        "        \"DO NOT ask for the entire RFP, only interact with it by asking questions and searching keywords\"\n",
        "        \"DO NOT repeat questions, only ask one question once and only search a single keyword once.\"\n",
        "        \"Ask a maximum of 2-3 questions\"\n",
        "    ),\n",
        "    verbose = True,\n",
        "    memory = True,\n",
        "    llm = assesser.llm,\n",
        "    tools = [Assesser,  write_to_file],\n",
        "    max_iterations = 5\n",
        "\n",
        ")\n",
        "summarise_usecases = Task(\n",
        "    description=(\n",
        "        \"Ask questions relevant to you from the data using the tools assigned. You need to find all cases relevant to you as part of the {team_name} team\"\n",
        "        \"The RFP does not answer all questions. Where the answers are unavailable, you make educated assumptions and move on.\"\n",
        "        \"You assess these documents to see where you, being part of the {team_name} team, can help solve some, if any, of these problems\"\n",
        "        ),\n",
        "    expected_output = \"A summary in markdown syntax detailing the use-cases that are relevant to your field, along with their page-numbers. Write these files using write_to_file tool\",\n",
        "    agent = agent,\n",
        "    tools = [Assesser, write_to_file]\n",
        ")\n",
        "\n",
        "researcher = Agent(\n",
        "    role = \"Research Assistant\",\n",
        "    goal = \"You will provide cutting edge solutions to the problems presented to you by RFP Assesser\",\n",
        "    backstory = (\n",
        "        \"Your coworker, RFP Assesser, has assessed the client's RFP and come up with potential places where {team_name} can be used\"\n",
        "        \"You have access to a search tool which you can use to find relevant literature online\"\n",
        "        \"You need to summarise each use-case into an achievable target\"\n",
        "        \"Then you will search online to find relevant literature that will help you orchestrate each of these solutions\"\n",
        "    ),\n",
        "    verbose = True,\n",
        "    memory = True,\n",
        "    llm = assesser.llm\n",
        ")\n",
        "\n",
        "specifying_task = Task(\n",
        "    description = (\n",
        "        \"You are provided with a holistic view of where the client wants to make improvements.\"\n",
        "        \"You need to {num_solutions} solutions from these potential use-cases\"\n",
        "        \"You need to be very specific about what problem is being solved and how its being solved\"\n",
        "    ),\n",
        "    expected_output = \"A title and a summary for each usecase presented, using the information gathered by your coworker RFP Assesser\",\n",
        "    agent = researcher\n",
        ")\n",
        "\n",
        "literature_review = Task(\n",
        "    description = (\n",
        "        \"Now that you have specific tasks, you have been given the tools to search online for relevant literature\"\n",
        "        \"Search whatever you think is relevant and support your use-cases with proper literature review\"\n",
        "    ),\n",
        "    expected_output = \"Title for each usecase with a paragraph and a URL to link each solution with relevant literature\",\n",
        "    agent = researcher,\n",
        "    tools = [DuckDuckGoSearch]\n",
        ")\n",
        "\n",
        "crew = Crew(\n",
        "    agents = [rfp_assesser, researcher],\n",
        "    tasks = [summarise_usecases, specifying_task, literature_review],\n",
        "    process = Process.sequential\n",
        ")\n",
        "result = crew.kickoff(inputs={'team_name': 'Data Science, AI and Machine Learning',\n",
        "                     'team_tools': 'Data Science, AI and ML',\n",
        "                              'num_solutions':'4'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4d0O_u6rNEt"
      },
      "outputs": [],
      "source": [
        "display(Markdown(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom MultiAgent workflow I created Myself in OOP"
      ],
      "metadata": {
        "id": "6cVAV_G8Irvu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftuNlCRN3Yyl"
      },
      "outputs": [],
      "source": [
        "\n",
        "questions = [\n",
        "    \"Can you give requirements of the client?\",\n",
        "    \"What platform does client expect us to use? If the client does not mention explicitly, can you recommend one?\",\n",
        "    ]\n",
        "# result = assesser.run(\"Can you give requirements of the client?\")\n",
        "# result = assesser.run(\"What platform does client expect us to use? If the client does not mention explicitly, can you recommend one?\")\n",
        "# result = assesser.run(\"\"\"\n",
        "# Assume you are a data science consultant assessing the RFP.\n",
        "# Create a list of all usecases that can be proposed to the client\n",
        "# based on what they have mentioned about their needs in the RFP.\"\"\")\n",
        "\n",
        "# result = assesser.run(\"\"\"\n",
        "# Assume you are a data science consultant assessing the RFP.\n",
        "# Create a list of all usecases that can be proposed to the client relating to data science, ai or machine learning\n",
        "# based on what they have mentioned about their needs in the RFP.\n",
        "# If there arent any usecases by the client, please recommend some\"\"\")\n",
        "class customAgent:\n",
        "  def __init__(self, llm, rag, max_iterations, goal, backstory):\n",
        "    self.rag = rag\n",
        "    self.llm = llm\n",
        "    self.max_iterations = max_iterations\n",
        "    self.goal = goal\n",
        "    self.backstory = backstory\n",
        "    self.previous_interactions = \"\"\n",
        "    self.prompt = None\n",
        "    self.task = None\n",
        "    self.question = None\n",
        "    self.answer = None\n",
        "    self.final_output = None\n",
        "  def ask_question(self):\n",
        "    for i in range(self.max_iterations):\n",
        "      self.prompt = f\"\"\"\n",
        "        You are an agent and you will be assigned a task.\n",
        "        Your backstory is: {self.backstory}\n",
        "        Your goal is: {self.goal}\n",
        "        Your previous interactions are: {self.previous_interactions}\n",
        "        You get to ask the client only {self.max_iterations} questions so be very specific and concise.\n",
        "      \"\"\"\n",
        "      self.task = \"Please respond with a single question\"\n",
        "      self.prompt = self.prompt+self.task\n",
        "      self.question = self.llm.invoke(self.prompt).content\n",
        "      # print(self.question)\n",
        "      self.answer = self.rag.run(self.question)\n",
        "      # print(self.answer)\n",
        "      # print(\"===========================================================================\")\n",
        "      self.previous_interactions += f\"Question: {self.question}\\nAnswer: {self.answer}\\n\\n\"\n",
        "    self.prompt = f\"\"\"\n",
        "        You are an agent and you will be assigned a task.\n",
        "        Your backstory is: {self.backstory}\n",
        "        Your goal is: {self.goal}\n",
        "        Your previous interactions are: {self.previous_interactions}\n",
        "        You get to ask the client only {self.max_iterations} questions so be very specific and concise.\n",
        "      \"\"\"\n",
        "    self.task = \"Please suggest your solution now based on your assessment of the client based on your interactions. Ask any relevant questions that can be forwarded to the client\"\n",
        "    self.prompt = self.prompt+self.task\n",
        "    self.final_output = self.llm.invoke(self.prompt).content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "agent = customAgent(\n",
        "    llm = assesser.llm,\n",
        "    rag = assesser,\n",
        "    max_iterations = 15,\n",
        "    goal = \"\"\"\n",
        "        Your goal is to find use cases related to data science, AI and machine learning.\n",
        "        Find atleast 6 usecases.\n",
        "        Do not be generic, be specific with your usecases.\n",
        "        Give your output in the format <Usecase Name>: <Brief Detail>\n",
        "        \"\"\",\n",
        "    backstory = \"\"\"\n",
        "    You are a data science consultant.\n",
        "    You have access to a tool which is a retrieval augmented generator\n",
        "    This tool has read the documents sent over by the client and acts as the owner of the PDFs\n",
        "    You can ask it relevant questions related to the document to determine where you can intervene.\n",
        "    You cannot ask the same question more than once.\n",
        "    \"\"\")\n",
        "agent.ask_question()\n",
        "display(Markdown(agent.final_output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwYxuZqkNJU9"
      },
      "outputs": [],
      "source": [
        "display(Markdown(agent.previous_interactions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYt1BoJuMUflNMR9PL3Ptd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}